# ë„¤ì´ë²„ ë¸”ë¡œê·¸ AI íƒì§€ ëª¨ë¸ ê³„íš 2.0

> **ì´ˆì†Œí˜• íŠ¸ëœìŠ¤í¬ë¨¸ + í•©ì„± ë°ì´í„° + From Scratch í•™ìŠµ**

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš” ë° ë™ê¸°](#ê°œìš”-ë°-ë™ê¸°)
2. [ê¸°ìˆ  ìŠ¤íƒ](#ê¸°ìˆ -ìŠ¤íƒ)
3. [ë°ì´í„° íŒŒì´í”„ë¼ì¸](#ë°ì´í„°-íŒŒì´í”„ë¼ì¸)
4. [ëª¨ë¸ ì•„í‚¤í…ì²˜](#ëª¨ë¸-ì•„í‚¤í…ì²˜)
5. [í•™ìŠµ ì „ëµ](#í•™ìŠµ-ì „ëµ)
6. [í‰ê°€ ë° ìµœì í™”](#í‰ê°€-ë°-ìµœì í™”)
7. [CoreML ë³€í™˜](#coreml-ë³€í™˜)
8. [íƒ€ì„ë¼ì¸ ë° ë¹„ìš©](#íƒ€ì„ë¼ì¸-ë°-ë¹„ìš©)
9. [ì‹¤í–‰ ê³„íš](#ì‹¤í–‰-ê³„íš)

---

## ê°œìš” ë° ë™ê¸°

### ê¸°ì¡´ ëª¨ë¸ (v1.0)ì˜ í•œê³„

| í•­ëª© | ê¸°ì¡´ ëª¨ë¸ | ë¬¸ì œì  |
|------|----------|--------|
| ì•Œê³ ë¦¬ì¦˜ | TF-IDF + Logistic Regression | ë¬¸ë§¥ ì´í•´ ë¶ˆê°€ (ë‹¨ì–´ ë¹ˆë„ë§Œ) |
| ë°ì´í„° | 297ê°œ ìŠ¤ë‹ˆí« | í•™ìŠµ ë°ì´í„° ë¶€ì¡± |
| íŠ¹ì§• ì¶”ì¶œ | Character-level bigram | ì˜ë¯¸ íŒŒì•… ë¶ˆê°€ |
| ì •í™•ë„ | 95% (test) | ê³¼ì í•© ìœ„í—˜ (ë°ì´í„° ì ìŒ) |

### ìƒˆë¡œìš´ ì ‘ê·¼ (v2.0)

**í•µì‹¬ ì•„ì´ë””ì–´**: "ë°©ëŒ€í•œ ë°ì´í„°ë¡œ ì‘ì§€ë§Œ ë˜‘ë˜‘í•œ ëª¨ë¸ì„ ë§Œë“¤ì"

```
ì‹¤ì œ ë°ì´í„° (297ê°œ)
    â†“
Gemini Flashë¡œ í•©ì„± ë°ì´í„° ìƒì„± (10,000ê°œ)
    â†“
ì´ 10,297ê°œ í•™ìŠµ ë°ì´í„°
    â†“
TinyTransformer ì²˜ìŒë¶€í„° í•™ìŠµ (From Scratch)
    â†“
ìµœì í™” (INT4 Quantization, Pruning)
    â†“
ìµœì¢… ëª¨ë¸ (CoreML, 5-10MB) â†’ Safari Extension
```

### ëª©í‘œ

| ëª©í‘œ í•­ëª© | ëª©í‘œ ê°’ | ê·¼ê±° |
|----------|---------|------|
| ëª¨ë¸ í¬ê¸° | 5-10 MB | Safari Extension í—ˆìš© ë²”ìœ„ |
| ì¶”ë¡  ì†ë„ | < 50ms | ê²€ìƒ‰ ê²°ê³¼ 10-20ê°œ ì‹¤ì‹œê°„ |
| ì •í™•ë„ | > 88% | ì‹¤ìš©ì  íƒì§€ ì„±ëŠ¥ |
| ë°ì´í„° | 10,000+ ìƒ˜í”Œ | ê³¼ì í•© ë°©ì§€ |

---

## ê¸°ìˆ  ìŠ¤íƒ

### ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬

```yaml
core:
  - PyTorch 2.5+          # ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ (2025ë…„ ìµœì‹ )
  - Transformers 4.50+    # Hugging Face íŠ¸ëœìŠ¤í¬ë¨¸ (2025ë…„ ìµœì‹ )
  - coremltools 8.0+      # CoreML ë³€í™˜ (2025ë…„ ìµœì‹ )

data_generation:
  - Google Gemini Flash (gemini-flash-latest) â­
    * ìš©ë„: í•©ì„± ë°ì´í„° ìƒì„± ONLY
    * 2ë°° ë¹ ë¥¸ ì†ë„ (vs Gemini 1.5 Pro)
    * 1M í† í° ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°
    * API í¬ë ˆë”§ í™œìš©

tokenizer:
  modern_korean:
    - Solar Pro 2 tokenizer      # Upstage ìµœì‹  (2024) â­
    - Exaone 4.0 tokenizer       # LG AI Research (2024)
  fallback:
    - sentencepiece              # ë²”ìš© í† í¬ë‚˜ì´ì €
    - kobert-tokenizer           # KoBERT í† í¬ë‚˜ì´ì €
```

### ê°œë°œ í™˜ê²½

```bash
# Python í™˜ê²½
Python 3.9+
pip install torch transformers coremltools sentencepiece
pip install datasets accelerate  # í•™ìŠµ ê°€ì†
```

---

## ë°ì´í„° íŒŒì´í”„ë¼ì¸

### Phase 1: ì‹¤ì œ ë°ì´í„° (ê¸°ì¡´)

```
í˜„ì¬ ë°ì´í„°: 297ê°œ ìŠ¤ë‹ˆí«
  - AI ë¼ë²¨: ~150ê°œ
  - HUMAN ë¼ë²¨: ~150ê°œ
  - ì¶œì²˜: Data-Preprocessing/data/processed/training_data.json
```

### Phase 2: í•©ì„± ë°ì´í„° ìƒì„± (Synthetic Data)

**ìƒì„± ë„êµ¬**: Google Gemini Flash (gemini-flash-latest)

**Gemini Flash ì„ íƒ ì´ìœ **:
- âš¡ **ì†ë„**: 1.5 Pro ëŒ€ë¹„ 2ë°° ë¹ ë¦„ â†’ ë°ì´í„° ìƒì„± ì‹œê°„ ë‹¨ì¶•
- ğŸ“Š **ì»¨í…ìŠ¤íŠ¸**: 1M í† í° â†’ ê¸´ ë¸”ë¡œê·¸ ê¸€ë„ ì™„ë²½ ì²˜ë¦¬
- ğŸ’° **ë¹„ìš©**: API í¬ë ˆë”§ í™œìš© ê°€ëŠ¥
- ğŸ¯ **í’ˆì§ˆ**: ë©€í‹°ëª¨ë‹¬ ì…ì¶œë ¥ â†’ ë†’ì€ í’ˆì§ˆì˜ ë³€í˜• ìƒì„±
- ğŸ”„ **ì¼ê´€ì„±**: ë‹¨ì¼ ëª¨ë¸ ì‚¬ìš©ìœ¼ë¡œ ìŠ¤íƒ€ì¼ ì¼ê´€ì„± ìœ ì§€

**ìƒì„± ì „ëµ**:
1. **Paraphrasing** (ì˜ì—­): ê¸°ì¡´ 297ê°œ â†’ ê° 5ê°œ ë³€í˜• = 1,485ê°œ
2. **Style Transfer** (ìŠ¤íƒ€ì¼ ë³€í™˜): AI ìŠ¤íƒ€ì¼ â†” HUMAN ìŠ¤íƒ€ì¼
3. **Augmentation** (ì¦ê°•): ê¸¸ì´, ì–´ì¡°, ë‹¨ì–´ ì„ íƒ ë³€í˜•
4. **Zero-shot Generation** (ìƒˆ ìƒ˜í”Œ): ì™„ì „íˆ ìƒˆë¡œìš´ ë¸”ë¡œê·¸ ê¸€ ìƒì„±

**ì˜ˆì‹œ**:

```python
# ì›ë³¸ (HUMAN)
"ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ê°€ ì •ë§ ì¢‹ë„¤ìš”. ì‚°ì±…í•˜ê¸° ë”± ì¢‹ì€ ë‚ ì´ì—ìš”!"

# Gemini Flash ìƒì„± ë³€í˜•
ë³€í˜• 1: "ì„œìš¸ ë‚ ì”¨ê°€ ë„ˆë¬´ ì¢‹ì•„ì„œ ë°–ì— ë‚˜ê°€ê³  ì‹¶ì–´ìš”!"
ë³€í˜• 2: "ìš”ì¦˜ ë‚ ì”¨ ì§„ì§œ ì¢‹ë‹¤. ì‚°ì±… ê°€ì•¼ê² ë‹¤."
ë³€í˜• 3: "ì˜¤ëŠ˜ê°™ì´ í™”ì°½í•œ ë‚ ì—” ì•¼ì™¸ í™œë™ì´ ìµœê³ ì£ ."
ë³€í˜• 4: "ì„œìš¸ í•˜ëŠ˜ì´ ì •ë§ ë§‘ë„¤ìš”. ë‚˜ë“¤ì´ ê°€ê¸° ì¢‹ì€ ë‚ ì”¨ì…ë‹ˆë‹¤."
ë³€í˜• 5: "ì´ëŸ° ë‚ ì”¨ì—” ì§‘ì—ë§Œ ìˆê¸° ì•„ê¹ì£ ? ì‚°ì±… ê³ ê³ !"
```

**ëª©í‘œ**: 10,000ê°œ í•©ì„± ìƒ˜í”Œ ìƒì„±

### Phase 3: ë°ì´í„° ê²€ì¦ ë° í•„í„°ë§

```python
# í’ˆì§ˆ ê²€ì¦
def validate_synthetic_data(sample):
    checks = [
        len(sample['text']) > 50,           # ìµœì†Œ ê¸¸ì´
        len(sample['text']) < 500,          # ìµœëŒ€ ê¸¸ì´
        has_korean(sample['text']),         # í•œêµ­ì–´ í¬í•¨
        not duplicate(sample['text']),      # ì¤‘ë³µ ì œê±°
    ]
    return all(checks)
```

### ìµœì¢… ë°ì´í„°ì…‹

| êµ¬ë¶„ | ì‹¤ì œ ë°ì´í„° | í•©ì„± ë°ì´í„° | í•©ê³„ |
|------|------------|------------|------|
| Train | 237 | 8,000 | 8,237 |
| Validation | 30 | 1,000 | 1,030 |
| Test | 30 | 1,000 | 1,030 |
| **ì´ê³„** | **297** | **10,000** | **10,297** |

---

## ëª¨ë¸ ì•„í‚¤í…ì²˜

### TinyTransformer (From Scratch)

**ì„¤ê³„ ëª©í‘œ**: ìµœì¢… 5-10MB (INT4 ì–‘ìí™”), < 50ms ì¶”ë¡ 

**ì°¸ê³  ëª¨ë¸**: TinyBERT-4 (2025ë…„ ì—°êµ¬)
- 14.5M params, 55MB (FP32), GLUE 77ì 
- ì—ë„ˆì§€ íš¨ìœ¨ 91.26% í–¥ìƒ (vs BERT-Base)
- ì¶”ë¡  ì†ë„ 9.4ë°° ë¹ ë¦„

```python
model_config = {
    "vocab_size": 8000,           # í•œêµ­ì–´ í† í¬ë‚˜ì´ì € (Solar/Exaone)
    "hidden_size": 312,           # ì„ë² ë”© ì°¨ì› (BERT: 768, TinyBERT: 312)
    "num_hidden_layers": 4,       # ë ˆì´ì–´ ìˆ˜ (BERT: 12, TinyBERT: 4)
    "num_attention_heads": 12,    # ì–´í…ì…˜ í—¤ë“œ (BERT: 12)
    "intermediate_size": 1200,    # FFN í¬ê¸° (BERT: 3072, TinyBERT: 1200)
    "max_position_embeddings": 128, # ìµœëŒ€ í† í° (BERT: 512)
    "type_vocab_size": 2,         # ì„¸ê·¸ë¨¼íŠ¸ íƒ€ì…
    "num_labels": 2,              # AI / HUMAN
}

# ì¶”ì • íŒŒë¼ë¯¸í„° ìˆ˜: ~15M (ì•½ 60MB FP32 â†’ 15MB INT4 â†’ 5-10MB ìµœì¢…)
```

### ëª¨ë¸ êµ¬ì¡°

```
ì…ë ¥: "ì œëª© + ìŠ¤ë‹ˆí«" (ìµœëŒ€ 128 í† í°)
  â†“
[Tokenizer] (SentencePiece 8K vocab)
  â†“
[Embedding Layer] (312 dim)
  â†“
[4x Transformer Blocks]
  â”œâ”€ Multi-Head Attention (12 heads)
  â”œâ”€ Feed-Forward Network (1200 â†’ 312)
  â””â”€ Layer Normalization
  â†“
[CLS Token] â†’ Classification Head (2-way: AI/HUMAN)
  â†“
ì¶œë ¥: [AI í™•ë¥ , HUMAN í™•ë¥ ]
```

### ê²½ëŸ‰í™” ê¸°ë²• (2024-2025 ìµœì‹ )

1. **INT4 Quantization** (4ë¹„íŠ¸ ì–‘ìí™”) - CoreML 8.0+ ì§€ì›
   - FP32 (60MB) â†’ INT4 (15MB) = **75% í¬ê¸° ê°ì†Œ**
   - Per-block quantizationìœ¼ë¡œ ì •í™•ë„ ìœ ì§€
   - Apple Silicon Neural Engine ìµœì í™”

2. **W8A8 Mode** (ê°€ì¤‘ì¹˜+í™œì„±í™” 8ë¹„íŠ¸) - A17 Pro/M4+ ì „ìš©
   - INT8 ê°€ì¤‘ì¹˜ + INT8 í™œì„±í™”
   - Neural Engine ê°€ì† ì—°ì‚° ê²½ë¡œ
   - ì¶”ë¡  ì†ë„ ì¶”ê°€ í–¥ìƒ (30-50%)

3. **Pruning** (ê°€ì§€ì¹˜ê¸°)
   - ì¤‘ìš”ë„ ë‚®ì€ ë‰´ëŸ° ì œê±° (30% ê°€ì§€ì¹˜ê¸°)
   - Sparse í–‰ë ¬ í‘œí˜„ìœ¼ë¡œ íš¨ìœ¨ì  ì €ì¥
   - ì •í™•ë„ í•˜ë½ < 1%

4. **GPTQ** (ìƒì„±í˜• ëª¨ë¸ìš© ì–‘ìí™”) - 2024 ìµœì‹ 
   - Generative Pre-trained Transformersìš© ì •ë°€ ì–‘ìí™”
   - 4-bit ì–‘ìí™”ì—ì„œë„ ë†’ì€ ì •í™•ë„ ìœ ì§€

---

## í•™ìŠµ ì „ëµ

### From Scratch í•™ìŠµ (ì²˜ìŒë¶€í„°)

**í•µì‹¬ ì „ëµ**: 10,297ê°œì˜ ë°©ëŒ€í•œ ë°ì´í„°ë¡œ ëª¨ë¸ì„ ì²˜ìŒë¶€í„° í•™ìŠµ

**ì™œ From Scratchì¸ê°€?**
- âœ… **ê°„ë‹¨í•¨**: ë³µì¡í•œ Knowledge Distillation ë¶ˆí•„ìš”
- âœ… **ë¹„ìš© ì ˆê°**: Soft Label ìƒì„± ë¶ˆí•„ìš” ($30-50 ì ˆê°)
- âœ… **ì¶©ë¶„í•œ ë°ì´í„°**: 10,297ê°œ ë°ì´í„°ë©´ ê³¼ì í•© ì—†ì´ í•™ìŠµ ê°€ëŠ¥
- âœ… **ë¹ ë¥¸ ê°œë°œ**: íŒŒì´í”„ë¼ì¸ ë‹¨ìˆœí™”ë¡œ ê°œë°œ ê¸°ê°„ ë‹¨ì¶•

### í•™ìŠµ í•˜ì´í¼íŒŒë¼ë¯¸í„°

```yaml
training:
  epochs: 10-15              # ì¶©ë¶„í•œ í•™ìŠµ
  batch_size: 32
  learning_rate: 5e-4
  warmup_steps: 500
  weight_decay: 0.01

optimization:
  optimizer: AdamW
  scheduler: cosine
  gradient_accumulation: 4
  mixed_precision: fp16      # 2ë°° ì†ë„ í–¥ìƒ

regularization:
  dropout: 0.1
  label_smoothing: 0.1       # ê³¼ì í•© ë°©ì§€
  max_grad_norm: 1.0

early_stopping:
  patience: 3                # 3 epoch ê°œì„  ì—†ìœ¼ë©´ ì¤‘ë‹¨
  monitor: validation_loss
```

### í•™ìŠµ íŒŒì´í”„ë¼ì¸

```python
from transformers import AutoModelForSequenceClassification, Trainer

# 1. ëª¨ë¸ ì´ˆê¸°í™” (ì²˜ìŒë¶€í„°)
model = AutoModelForSequenceClassification.from_config(
    config=model_config,
    num_labels=2  # AI, HUMAN
)

# 2. ë°ì´í„° ë¡œë“œ (10,297ê°œ)
train_dataset = load_dataset(train_data)  # 8,237ê°œ
val_dataset = load_dataset(val_data)      # 1,030ê°œ

# 3. í•™ìŠµ (From Scratch)
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
)

trainer.train()  # ì²˜ìŒë¶€í„° í•™ìŠµ!

# 4. ì €ì¥
model.save_pretrained("models/tinybert-blog-detector")
```

---

## í‰ê°€ ë° ìµœì í™”

### í‰ê°€ ë©”íŠ¸ë¦­

```python
metrics = {
    "accuracy": 0.88,              # ì „ì²´ ì •í™•ë„ (ëª©í‘œ)
    "precision": 0.87,             # AI íƒì§€ ì •ë°€ë„
    "recall": 0.89,                # AI íƒì§€ ì¬í˜„ìœ¨
    "f1_score": 0.88,              # F1 ì ìˆ˜
    "auc_roc": 0.92,               # ROC AUC
    "inference_time": "45ms",      # ì¶”ë¡  ì†ë„
    "model_size": "60MB (FP32)",   # ìµœì í™” ì „
}
```

### ìµœì í™” ë‹¨ê³„ (2024-2025 ìµœì‹  ê¸°ë²•)

**1ë‹¨ê³„: INT4 Quantization (4ë¹„íŠ¸ ì–‘ìí™”)** - CoreML 8.0+
```python
import coremltools as ct

# FP32 â†’ INT4 (per-block)
model_fp32 = load_model()  # 60MB
model_int4 = ct.optimize.coreml.linear_quantize_weights(
    model_fp32,
    mode="linear_symmetric",
    dtype=np.int4,          # 4-bit quantization
    granularity="per_block"  # per-block (ì •ë°€ë„â†‘)
)
# ê²°ê³¼: 15MB (75% ê°ì†Œ)
```

**2ë‹¨ê³„: W8A8 Mode** (Neural Engine ìµœì í™”) - A17 Pro/M4+
```python
# INT8 ê°€ì¤‘ì¹˜ + INT8 í™œì„±í™”
model_w8a8 = ct.optimize.coreml.linear_quantize_activations(
    model_int4,
    mode="linear_symmetric",
    dtype=np.int8
)
# Neural Engine ê°€ì†: ì¶”ë¡  ì†ë„ 30-50% í–¥ìƒ
```

**3ë‹¨ê³„: Pruning (ê°€ì§€ì¹˜ê¸°)**
```python
from torch.nn.utils import prune

# ì¤‘ìš”ë„ ë‚®ì€ ë‰´ëŸ° ì œê±°
pruned_model = prune.l1_unstructured(model, amount=0.3)  # 30% ì œê±°
# ì •í™•ë„ í•˜ë½ < 1%, í¬ê¸° ì¶”ê°€ 30% ê°ì†Œ
```

**4ë‹¨ê³„: GPTQ (ìƒì„±í˜• ëª¨ë¸ìš© ì–‘ìí™”)** - 2024 ìµœì‹ 
```python
from auto_gptq import AutoGPTQForCausalLM

# GPTQ ì–‘ìí™” (4-bit, ë†’ì€ ì •í™•ë„ ìœ ì§€)
quantized_model = AutoGPTQForCausalLM.from_pretrained(
    model,
    quantize_config={"bits": 4, "group_size": 128}
)
# 4-bitì—ì„œë„ ê±°ì˜ FP32 ìˆ˜ì¤€ ì •í™•ë„
```

**ìµœì¢… í¬ê¸° ì˜ˆìƒ**:
```
FP32 (60MB)
  â†’ INT4 per-block (15MB, -75%)
  â†’ Pruning (10MB, -83%)
  â†’ ìµœì¢… ëª¨ë¸: 5-10MB âœ…
```

---

## CoreML ë³€í™˜

### ë³€í™˜ íŒŒì´í”„ë¼ì¸

```
PyTorch Model (.pth)
  â†“
ONNX Format (.onnx)
  â†“ coremltools
CoreML Model (.mlmodel)
  â†“ Xcode
Safari Extension
```

### ë³€í™˜ ì½”ë“œ (CoreML 8.0+ ìµœì‹  ê¸°ëŠ¥)

```python
import coremltools as ct
import torch

# 1. PyTorch â†’ ONNX
torch.onnx.export(
    model,
    dummy_input,
    "model.onnx",
    input_names=["text"],
    output_names=["probabilities"],
    opset_version=17,  # ìµœì‹  opset
)

# 2. ONNX â†’ CoreML
mlmodel = ct.converters.onnx.convert(
    model="model.onnx",
    minimum_deployment_target=ct.target.macOS14,  # macOS 14+ (Neural Engine)
    compute_precision=ct.precision.FLOAT16,
)

# 3. INT4 Quantization ì ìš© (CoreML 8.0+)
mlmodel_int4 = ct.optimize.coreml.linear_quantize_weights(
    mlmodel,
    mode="linear_symmetric",
    dtype=np.int4,
    granularity="per_block",  # per-block (ì •ë°€ë„ í–¥ìƒ)
)

# 4. W8A8 Mode í™œì„±í™” (ì„ íƒì , A17 Pro/M4+)
mlmodel_optimized = ct.optimize.coreml.linear_quantize_activations(
    mlmodel_int4,
    mode="linear_symmetric",
    dtype=np.int8,
)

# 5. ë©”íƒ€ë°ì´í„° ì¶”ê°€
mlmodel_optimized.short_description = "Naver Blog AI Detector v2.0"
mlmodel_optimized.author = "Your Name"
mlmodel_optimized.license = "MIT"
mlmodel_optimized.version = "2.0.0"

mlmodel_optimized.input_description["text"] = "Title + Snippet (max 128 tokens)"
mlmodel_optimized.output_description["probabilities"] = "[AI probability, HUMAN probability]"

# 6. ì €ì¥ (mlpackage í˜•ì‹)
mlmodel_optimized.save("BlogAIDetector.mlpackage")

# ìµœì¢… í¬ê¸° í™•ì¸
import os
size_mb = os.path.getsize("BlogAIDetector.mlpackage") / 1024 / 1024
print(f"ëª¨ë¸ í¬ê¸°: {size_mb:.2f} MB")  # ì˜ˆìƒ: 5-10 MB
```

**CoreML 8.0 ìµœì‹  ê¸°ëŠ¥**:
- âœ… INT4 per-block quantization
- âœ… W8A8 mode (Neural Engine)
- âœ… GPTQ ì•Œê³ ë¦¬ì¦˜ ì§€ì›
- âœ… macOS 14+ ìµœì í™”

### Swift í†µí•©

```swift
import CoreML

// 1. ëª¨ë¸ ë¡œë“œ
let model = try BlogAIDetector(configuration: MLModelConfiguration())

// 2. ì˜ˆì¸¡
let input = BlogAIDetectorInput(text: titleAndSnippet)
let output = try model.prediction(input: input)

// 3. ê²°ê³¼
let aiProbability = output.probabilities[0]  // AI í™•ë¥ 
let prediction = aiProbability > 0.5 ? "AI" : "HUMAN"
```

---

## íƒ€ì„ë¼ì¸ ë° ë¹„ìš©

### ê°œë°œ ë‹¨ê³„ (From Scratch ë°©ì‹)

| ë‹¨ê³„ | ì‘ì—… | ì†Œìš” ì‹œê°„ | ëˆ„ì  |
|------|------|----------|------|
| 1 | í•©ì„± ë°ì´í„° ìƒì„± (10,000ê°œ) | **2ì¼** âš¡ | 2ì¼ |
| 2 | ëª¨ë¸ ì•„í‚¤í…ì²˜ êµ¬í˜„ (TinyBERT-4 ê¸°ë°˜) | 2ì¼ | 4ì¼ |
| 3 | **From Scratch í•™ìŠµ** (10,297ê°œ) | **3ì¼** | 7ì¼ |
| 4 | ìµœì í™” (INT4, GPTQ, Pruning) | 2ì¼ | 9ì¼ |
| 5 | CoreML 8.0 ë³€í™˜ ë° í…ŒìŠ¤íŠ¸ | 2ì¼ | 11ì¼ |
| 6 | Swift í†µí•© ë° ê²€ì¦ | 2ì¼ | 13ì¼ |
| **ì´ê³„** | | **13ì¼** | |

**ê¸°ì¡´ ëŒ€ë¹„ ë‹¨ì¶•**: 16ì¼ â†’ 13ì¼ (**3ì¼ ë‹¨ì¶•!** âš¡)

### ì˜ˆì‚° (From Scratch ë°©ì‹)

| í•­ëª© | ë¹„ìš© | ê·¼ê±° |
|------|------|------|
| **Gemini Flash API** â­ | **$15-25** | 10,000ê°œ í•©ì„± ë°ì´í„° ìƒì„±ë§Œ |
| GPU í•™ìŠµ (Colab Pro+) | $50/ì›” | A100 GPU 2ì£¼ ì‚¬ìš© |
| **ì´ ì˜ˆì‚°** | **$15-75** | (Colab ë¬´ë£Œ ì‹œ $15-25) |

**Gemini Flash ì‚¬ìš©ì²˜**:
- âœ… **í•©ì„± ë°ì´í„° ìƒì„±**: 297ê°œ â†’ 10,000ê°œ ë³€í˜•
- âŒ Soft Label ìƒì„±: **ë¶ˆí•„ìš”** (From Scratch ë°©ì‹)

**ë¹„ìš© ì ˆê° í¬ì¸íŠ¸**:
- Gemini Flashë¡œ í•©ì„± ë°ì´í„°ë§Œ ìƒì„± â†’ **$15-25**
- Soft Label ìƒì„± ì œê±° â†’ **$30-50 ì ˆê°** ğŸ’°
- Colab ë¬´ë£Œ GPU ì‚¬ìš© ì‹œ ì´ ë¹„ìš© **$15-25**

### í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­

**ê°œë°œ í™˜ê²½**:
- GPU: NVIDIA RTX 3060 ì´ìƒ (12GB VRAM) ë˜ëŠ” Colab Pro+
- RAM: 16GB+
- ì €ì¥ê³µê°„: 50GB+

**ì¶”ë¡  í™˜ê²½** (Safari Extension):
- macOS 14.0+ (CoreML 8.0, Neural Engine ì§€ì›) â­
- Apple Silicon (M1/M2/M3/M4) ê¶Œì¥
- A17 Pro/M4+ ìµœì  (W8A8 mode ì§€ì›)
- Intel Mac í˜¸í™˜ (ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥)

---

## ì‹¤í–‰ ê³„íš

### ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
ML-Training/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ real/                        # ì‹¤ì œ ë°ì´í„° (297ê°œ)
â”‚   â”‚   â””â”€â”€ training_data.json
â”‚   â”œâ”€â”€ synthetic/                   # í•©ì„± ë°ì´í„° (10,000ê°œ)
â”‚   â”‚   â”œâ”€â”€ paraphrased.json
â”‚   â”‚   â”œâ”€â”€ style_transfer.json
â”‚   â”‚   â””â”€â”€ generated.json
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ train.json               # 8,237ê°œ
â”‚       â”œâ”€â”€ val.json                 # 1,030ê°œ
â”‚       â””â”€â”€ test.json                # 1,030ê°œ
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 1_generate_synthetic.py      # Geminië¡œ í•©ì„± ë°ì´í„°
â”‚   â”œâ”€â”€ 2_build_model.py             # TinyTransformer êµ¬í˜„
â”‚   â”œâ”€â”€ 3_train_from_scratch.py      # From Scratch í•™ìŠµ â­
â”‚   â”œâ”€â”€ 4_optimize.py                # Quantization, Pruning
â”‚   â”œâ”€â”€ 5_export_coreml.py           # CoreML ë³€í™˜
â”‚   â””â”€â”€ 6_evaluate.py                # ìµœì¢… í‰ê°€
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/                 # í•™ìŠµ ì²´í¬í¬ì¸íŠ¸
â”‚   â”œâ”€â”€ optimized/                   # ìµœì í™” ëª¨ë¸
â”‚   â””â”€â”€ coreml/
â”‚       â””â”€â”€ BlogAIDetector.mlpackage
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ model-plan-v2.md             # í˜„ì¬ ë¬¸ì„œ
    â””â”€â”€ training-log.md              # í•™ìŠµ ë¡œê·¸
```

### ì‹¤í–‰ ìˆœì„œ

```bash
# 1. í™˜ê²½ ì„¤ì •
pip install -r requirements-v2.txt

# 2. í•©ì„± ë°ì´í„° ìƒì„± (Gemini Flash)
python scripts/1_generate_synthetic.py \
    --real_data data/real/training_data.json \
    --output data/synthetic/ \
    --teacher gemini-flash-latest \
    --target_size 10000

# 3. ëª¨ë¸ í•™ìŠµ (From Scratch)
python scripts/3_train_from_scratch.py \
    --data data/processed/ \
    --model_config configs/tiny_transformer.yaml \
    --epochs 15 \
    --batch_size 32

# 4. ìµœì í™”
python scripts/4_optimize.py \
    --model models/checkpoints/best.pth \
    --quantize int4 \
    --prune 0.3

# 5. CoreML ë³€í™˜
python scripts/5_export_coreml.py \
    --model models/optimized/final.pth \
    --output models/coreml/BlogAIDetector.mlpackage

# 6. í‰ê°€
python scripts/6_evaluate.py \
    --model models/coreml/BlogAIDetector.mlpackage \
    --test_data data/processed/test.json
```

---

## ê¸°ëŒ€ íš¨ê³¼

### v1.0 ëŒ€ë¹„ ê°œì„  (From Scratch ë°©ì‹)

| ì§€í‘œ | v1.0 (TF-IDF) | v2.0 (TinyTransformer) | ê°œì„ ìœ¨ |
|------|---------------|----------------------|--------|
| ì •í™•ë„ | 95% | **88-90%** | -5~7% (ì¼ë°˜í™” ëŠ¥ë ¥â†‘) |
| ë¬¸ë§¥ ì´í•´ | âŒ | âœ… (Transformer) | **íšê¸°ì  ê°œì„ ** |
| ë°ì´í„° í¬ê¸° | 297 | 10,297 | **34ë°° ì¦ê°€** |
| ëª¨ë¸ í¬ê¸° | 0.1 MB | **5-10 MB** (INT4) | 50-100ë°° (í—ˆìš©) |
| ì¶”ë¡  ì†ë„ | 5ms | **< 50ms** | 10ë°° ëŠë¦¼ (í—ˆìš©) |
| í™•ì¥ì„± | ë‚®ìŒ | **ë†’ìŒ** | ì¬í•™ìŠµ ê°€ëŠ¥ |
| ì—ë„ˆì§€ íš¨ìœ¨ | - | **91% í–¥ìƒ** | TinyBERT ê¸°ë°˜ |
| ê°œë°œ ë³µì¡ë„ | ë‚®ìŒ | **ë‚®ìŒ** | From Scratch ë°©ì‹ |
| ë¹„ìš© | - | **$15-25** | Geminië§Œ ì‚¬ìš© |

### í•µì‹¬ ì¥ì 

1. **ë¬¸ë§¥ ì´í•´**: ë‹¨ì–´ ë¹ˆë„ â†’ ì˜ë¯¸ë¡ ì  ì´í•´
2. **ë°ì´í„° í™•ì¥**: 297ê°œ â†’ 10,297ê°œ (ê³¼ì í•© ë°©ì§€)
3. **ë‹¨ìˆœí•œ íŒŒì´í”„ë¼ì¸**: From Scratch í•™ìŠµ (ë³µì¡í•œ KD ë¶ˆí•„ìš”)
4. **ë¹„ìš© ì ˆê°**: Gemini í•©ì„± ë°ì´í„°ë§Œ ($15-25)
5. **ë¹ ë¥¸ ê°œë°œ**: 13ì¼ (ê¸°ì¡´ 16ì¼ ëŒ€ë¹„ 3ì¼ ë‹¨ì¶•)

### ë¦¬ìŠ¤í¬ ê´€ë¦¬

| ë¦¬ìŠ¤í¬ | ì™„í™” ì „ëµ |
|--------|----------|
| ëª¨ë¸ í¬ê¸° ì´ˆê³¼ | INT4 Quantization, Pruning |
| ì¶”ë¡  ì†ë„ ëŠë¦¼ | W8A8 Mode, Apple Silicon ìµœì í™” |
| í•©ì„± ë°ì´í„° í’ˆì§ˆ | í’ˆì§ˆ ê²€ì¦ í•„í„°ë§, ì¤‘ë³µ ì œê±° |
| ì •í™•ë„ ëª©í‘œ ë¯¸ë‹¬ | ë°ì´í„° ì¦ê°• ì¶”ê°€, Epoch ì¡°ì • |

---

## ê²°ë¡ 

### ìš”ì•½

**v2.0 í•µì‹¬ ì „ëµ (From Scratch)**:
1. **í•©ì„± ë°ì´í„°** (10,000ê°œ) â†’ Gemini Flashë¡œ ìƒì„±
2. **From Scratch í•™ìŠµ** â†’ 10,297ê°œë¡œ ì²˜ìŒë¶€í„° í•™ìŠµ
3. **ì´ˆì†Œí˜• íŠ¸ëœìŠ¤í¬ë¨¸** â†’ TinyBERT-4 ê¸°ë°˜ (5-10MB)
4. **ìµœì‹  ìµœì í™”** â†’ INT4, W8A8, GPTQ

### ê¸°ì¡´ ê³„íš ëŒ€ë¹„ ê°œì„ 

| í•­ëª© | ê¸°ì¡´ (KD ë°©ì‹) | ë³€ê²½ (From Scratch) |
|------|--------------|-------------------|
| **ë³µì¡ë„** | ë†’ìŒ (KD, Soft Label) | **ë‚®ìŒ** (ë‹¨ìˆœ í•™ìŠµ) |
| **ë¹„ìš©** | $80-100 | **$15-75** |
| **ê°œë°œ ê¸°ê°„** | 16ì¼ | **13ì¼** |
| **ì •í™•ë„** | 90-92% | **88-90%** |
| **ìœ ì§€ë³´ìˆ˜** | ì–´ë ¤ì›€ | **ì‰¬ì›€** |

### Next Steps

1. âœ… ê³„íš ìˆ˜ë¦½ (í˜„ì¬ ë¬¸ì„œ)
2. â³ í•©ì„± ë°ì´í„° ìƒì„± íŒŒì´í”„ë¼ì¸ êµ¬í˜„
3. â³ TinyTransformer ëª¨ë¸ êµ¬í˜„
4. â³ From Scratch í•™ìŠµ
5. â³ CoreML ë³€í™˜ ë° Swift í†µí•©

### ì°¸ê³  ìë£Œ

**ìµœì‹  ëª¨ë¸ ë° ê¸°ìˆ  (2024-2025)**:
- [Gemini Flash Documentation](https://ai.google.dev/gemini-api/docs/models) - Google
- [TinyBERT 2025 Research](https://arxiv.org/abs/1910.01108) - ì—ë„ˆì§€ íš¨ìœ¨ 91% í–¥ìƒ
- [CoreML 8.0 Optimization Guide](https://apple.github.io/coremltools/docs-guides/source/opt-overview.html)
- [GPTQ Quantization](https://arxiv.org/abs/2210.17323) - 4-bit ì •ë°€ ì–‘ìí™”

**í•œêµ­ì–´ NLP (2024-2025)**:
- [Solar Pro 2](https://www.upstage.ai/solar-pro) - Upstage, 31B params
- [Exaone 4.0](https://www.lgresearch.ai/exaone) - LG AI Research, 32B/1.2B
- [A.X 4.0](https://www.skt.ai/) - SK Telecom, GPT-4o ìˆ˜ì¤€ í•œêµ­ì–´ ì„±ëŠ¥
- [HyperClova X Think](https://www.navercorp.com/hyperclova) - Naver

**ê¸°ì´ˆ ë…¼ë¬¸**:
- [DistilBERT Paper](https://arxiv.org/abs/1910.01108)
- [MobileBERT Paper](https://arxiv.org/abs/2004.02984)

**êµ¬í˜„ ë„êµ¬**:
- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [CoreML Tools 8.0+](https://github.com/apple/coremltools) - INT4 quantization
- [Auto-GPTQ](https://github.com/PanQiWei/AutoGPTQ) - GPTQ ì–‘ìí™”

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-10-17 (From Scratch ë°©ì‹ìœ¼ë¡œ ì „ë©´ ìˆ˜ì •)
**ì‘ì„±ì**: Claude + User
**ë²„ì „**: 2.0 (From Scratch + 2024-2025 ìµœì‹  ê¸°ìˆ )
**í•™ìŠµ ë°©ì‹**: From Scratch (ì²˜ìŒë¶€í„° í•™ìŠµ)
**Teacher ëª¨ë¸**: gemini-flash-latest (í•©ì„± ë°ì´í„° ìƒì„± ì „ìš©)
