# ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ ê³„íš

> **ë™ì  ë°ì´í„° ì²˜ë¦¬**: ëª¨ë“  ë°ì´í„°ì…‹ í¬ê¸°ëŠ” ëŸ°íƒ€ì„ì— ê³„ì‚°ë˜ë©°, ì†Œê·œëª¨/ëŒ€ê·œëª¨ ë°ì´í„° ëª¨ë‘ ì§€ì›

## ğŸ¯ ëª©í‘œ

**Phase 1**: LLMìœ¼ë¡œ ì „ì²´ ë¸”ë¡œê·¸ ê¸€ì˜ AI/HUMAN íŒì •
**Phase 2**: ê° ê¸€ì„ 3~5ê°œ ìŠ¤ë‹ˆí«(100-300ì)ìœ¼ë¡œ ë¶„í•  â†’ í•™ìŠµ ë°ì´í„° ìƒì„±

## ğŸ“Š ë°ì´í„° íë¦„

```
blogs.json (Nê°œ)
   â†“ Gemini-2.5-flash-latest
labeled_blogs.json (Nê°œ + AI/HUMAN ë¼ë²¨)
   â†“ ìŠ¤ë‹ˆí« ë¶„í•  (í‰ê·  3.3x)
training_data.json (~3.3Nê°œ snippet)
```

**ë°ì´í„° í¬ê¸° ê³„ì‚° ë°©ì‹**:
- ì…ë ¥ í¬ê¸°: `N = len(blogs.json)`
- ë¼ë²¨ë§ ì¶œë ¥: `Nê°œ`
- ìŠ¤ë‹ˆí« ì¶œë ¥: `~3.3Nê°œ` (ê¸€ ê¸¸ì´ì— ë”°ë¼ 3~5ê°œ ë¶„í• )

## ğŸ“ ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
Data-Collection/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ blogs.json                    # ì›ë³¸ ìŠ¤í¬ë© ë°ì´í„°
â”‚   â”œâ”€â”€ labeled/
â”‚   â”‚   â””â”€â”€ labeled_blogs.json        # LLM ë¼ë²¨ë§ ì™„ë£Œ
â”‚   â””â”€â”€ processed/
â”‚       â””â”€â”€ training_data.json        # ìŠ¤ë‹ˆí« ë¶„í•  ì™„ë£Œ
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ scraper.py                    # (ê¸°ì¡´) ë¸”ë¡œê·¸ ìŠ¤í¬ë˜í•‘
â”‚   â”œâ”€â”€ labeler.py                    # (ì‹ ê·œ) LLM ìë™ ë¼ë²¨ë§
â”‚   â””â”€â”€ preprocess.py                 # (ì‹ ê·œ) ìŠ¤ë‹ˆí« ë¶„í• 
â”‚
â”œâ”€â”€ prompts/
â”‚   â””â”€â”€ labeling_prompt.md            # AI íŒë‹¨ ê¸°ì¤€ í”„ë¡¬í”„íŠ¸
â”‚
â””â”€â”€ docs/
    â””â”€â”€ preprocessing-plan.md         # í˜„ì¬ íŒŒì¼
```

## ğŸ”§ Phase 1: LLM ë¼ë²¨ë§ (`labeler.py`)

### ì…ë ¥
- `data/blogs.json` (ë™ì  í¬ê¸° N)
- `prompts/labeling_prompt.md` (ë™ì  ë¡œë“œ)

### ì²˜ë¦¬
- Gemini-2.5-flash-latest API í˜¸ì¶œ
- ì…ë ¥: `title` + `full_text` (ì „ì²´ ë³¸ë¬¸)
- íŒë‹¨ ê¸°ì¤€: í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë‚´ìš©
- **ë°°ì¹˜ ì²˜ë¦¬**: 10ê°œì”© API í˜¸ì¶œ (rate limit ê³ ë ¤)

### ì¶œë ¥ ìŠ¤í‚¤ë§ˆ (`data/labeled/labeled_blogs.json`)
```json
[
  {
    "blog_id": "blog_0059",
    "url": "https://...",
    "title": "ì•Œë¡œì— í‚¤ìš°ê¸° ì¢…ë¥˜...",
    "full_text": "ì „ì²´ ë³¸ë¬¸...",
    "keyword": "ì•Œë¡œì— í‚¤ìš°ê¸°",
    "scraped_at": "2025-10-16T18:01:41.295688",
    "duplicate_count": 0,
    "last_seen_at": "2025-10-16T18:01:41.295688",

    "label": "AI",
    "confidence": 0.85,
    "reasoning": "ë°˜ë³µì ì¸ í‚¤ì›Œë“œ ë‚˜ì—´ê³¼ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ êµ¬ì¡°...",
    "labeled_at": "2025-10-16T19:00:00.123456"
  }
]
```

**í•„ë“œ ì„¤ëª…**:
- `label`: `"AI"` | `"HUMAN"`
- `confidence`: `0.0 ~ 1.0` (LLMì˜ í™•ì‹ ë„)
- `reasoning`: íŒë‹¨ ê·¼ê±° (100ì ì´ë‚´)
- `labeled_at`: ë¼ë²¨ë§ ì‹œê° (ISO 8601)

### í”„ë¡¬í”„íŠ¸ ì„¤ê³„ (`prompts/labeling_prompt.md`)

```markdown
# AI ë¸”ë¡œê·¸ ê¸€ íŒë‹¨ ê¸°ì¤€

ë‹¹ì‹ ì€ ë„¤ì´ë²„ ë¸”ë¡œê·¸ ê¸€ì´ AIë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨í•˜ì„¸ìš”:

## AI ìƒì„± ê¸€ì˜ íŠ¹ì§•
1. **í‚¤ì›Œë“œ ë°˜ë³µ**: ë™ì¼ í‚¤ì›Œë“œê°€ ë¶€ìì—°ìŠ¤ëŸ½ê²Œ ë°˜ë³µ
2. **í˜•ì‹ì  êµ¬ì¡°**: ì„œë¡ -ë³¸ë¡ -ê²°ë¡ ì´ ê¸°ê³„ì ìœ¼ë¡œ êµ¬ë¶„
3. **ì´ëª¨ì§€ ê³¼ë‹¤**: ê° ë¬¸ë‹¨ë§ˆë‹¤ ì´ëª¨ì§€ ì‚¬ìš©
4. **ë‚˜ì—´ì‹ ë¬¸ì¥**: "~í•˜ê³ ìš”", "~ìˆì–´ìš”" ë“± ë‹¨ìˆœ ë‚˜ì—´
5. **ê´‘ê³ ì„± í‘œí˜„**: "ê¼­ í™•ì¸í•˜ì„¸ìš”", "ì¶”ì²œë“œë ¤ìš”" ë“±
6. **ë¶ˆí•„ìš”í•œ ê°•ì¡°**: íŠ¹ì • í‚¤ì›Œë“œì— **êµµì€ ê¸€ì”¨** ê³¼ë‹¤ ì‚¬ìš©

## ì¸ê°„ ì‘ì„± ê¸€ì˜ íŠ¹ì§•
1. **ìì—°ìŠ¤ëŸ¬ìš´ íë¦„**: ê°œì¸ ê²½í—˜ê³¼ ê°ì • í‘œí˜„
2. **êµ¬ì–´ì²´ ì‚¬ìš©**: "ê·¸ì¹˜ë§Œ", "ê·¼ë°", "ì†”ì§íˆ" ë“±
3. **ë§¥ë½ì  ì¼ê´€ì„±**: ì£¼ì œê°€ ìì—°ìŠ¤ëŸ½ê²Œ ì „ê°œ
4. **ë…íŠ¹í•œ í‘œí˜„**: ê°œì¸ë§Œì˜ ì–´íˆ¬ì™€ í‘œí˜„ ë°©ì‹
5. **ì¼ìƒì  ë””í…Œì¼**: êµ¬ì²´ì ì¸ ê°œì¸ ê²½í—˜ ë¬˜ì‚¬

## ì¶œë ¥ í˜•ì‹ (JSON)
ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ì˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”:
{
  "label": "AI" or "HUMAN",
  "confidence": 0.85,
  "reasoning": "íŒë‹¨ ê·¼ê±° (100ì ì´ë‚´)"
}
```

### API í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜

```python
def label_with_gemini(
    blog: Dict,
    prompt_template: str,
    api_key: str
) -> Dict:
    """Gemini APIë¡œ ë‹¨ì¼ ë¸”ë¡œê·¸ ê¸€ ë¼ë²¨ë§

    Args:
        blog: ì›ë³¸ ë¸”ë¡œê·¸ ë°ì´í„° (title, full_text í¬í•¨)
        prompt_template: prompts/labeling_prompt.md ë‚´ìš©
        api_key: Gemini API í‚¤

    Returns:
        ì›ë³¸ ë°ì´í„° + ë¼ë²¨ë§ ê²°ê³¼ (label, confidence, reasoning, labeled_at)
    """
    pass


def label_all_blogs(
    input_file: Path,
    output_file: Path,
    prompt_file: Path,
    api_key: str,
    batch_size: int = 10,
    limit: int = None  # í…ŒìŠ¤íŠ¸ìš©: ì²˜ìŒ Nê°œë§Œ ì²˜ë¦¬
) -> Dict[str, int]:
    """ì „ì²´ ë¸”ë¡œê·¸ ë°ì´í„° ë¼ë²¨ë§

    Args:
        input_file: data/blogs.json
        output_file: data/labeled/labeled_blogs.json
        prompt_file: prompts/labeling_prompt.md
        api_key: Gemini API í‚¤
        batch_size: API í˜¸ì¶œ ë°°ì¹˜ í¬ê¸°
        limit: í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ì œí•œ (Noneì´ë©´ ì „ì²´ ì²˜ë¦¬)

    Returns:
        í†µê³„ ì •ë³´ (total, ai_count, human_count, avg_confidence)
    """
    pass
```

## ğŸ”§ Phase 2: ìŠ¤ë‹ˆí« ë¶„í•  (`preprocess.py`)

### ì…ë ¥
- `data/labeled/labeled_blogs.json` (Nê°œ ë¼ë²¨ë§ ì™„ë£Œ)

### ì²˜ë¦¬ ë¡œì§

**1. ê¸€ ê¸¸ì´ ê¸°ë°˜ ë¶„í•  ê°œìˆ˜ ê²°ì •**:
```python
def get_num_snippets(text_length: int) -> int:
    """ê¸€ ê¸¸ì´ì— ë”°ë¥¸ ìŠ¤ë‹ˆí« ê°œìˆ˜ ê²°ì •"""
    if text_length < 500:
        return 3
    elif text_length < 1500:
        return 4
    else:
        return 5
```

**2. ìœ„ì¹˜ë³„ ìŠ¤ë‹ˆí« ì¶”ì¶œ**:
- ì‹œì‘ (0~20%)
- ì¤‘ê°„ (40~60%)
- ë (80~100%)
- ì¶”ê°€ ìœ„ì¹˜ ë™ì  ê³„ì‚°

**3. ìŠ¤ë‹ˆí« ê¸¸ì´ ì œì•½**:
- ìµœì†Œ: 100ì
- ìµœëŒ€: 300ì
- ë„¤ì´ë²„ ë¯¸ë¦¬ë³´ê¸° í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜

**4. ë¼ë²¨ ìƒì†**: ì›ë³¸ ê¸€ì˜ `label` (AI/HUMAN) ê·¸ëŒ€ë¡œ ì‚¬ìš©

### ì¶œë ¥ ìŠ¤í‚¤ë§ˆ (`data/processed/training_data.json`)

```json
[
  {
    "snippet_id": "blog_0059_01",
    "original_blog_id": "blog_0059",
    "title": "ì•Œë¡œì— í‚¤ìš°ê¸° ì¢…ë¥˜...",
    "snippet_text": "ë‹¤ìœ¡ì‹ë¬¼ 4ê°œì— ë§Œì› í•˜ëŠ”ë° ê·¸ ì¤‘ì—ì„œê³¨ë¼ì˜¨ ê²ƒì´ ë°”ë¡œ ì•Œë¡œì— ë² ë¼ í™”ë¶„ì´ì—ìš”...",
    "position": "start",
    "snippet_length": 150,
    "label": "AI",
    "confidence": 0.85,
    "keyword": "ì•Œë¡œì— í‚¤ìš°ê¸°",
    "created_at": "2025-10-16T20:00:00.123456"
  }
]
```

**í•„ë“œ ì„¤ëª…**:
- `snippet_id`: `{blog_id}_{ìˆœë²ˆ:02d}` í˜•ì‹
- `original_blog_id`: ì›ë³¸ ë¸”ë¡œê·¸ ì¶”ì ìš©
- `title`: ì›ë³¸ ê¸€ ì œëª© (ìŠ¤ë‹ˆí«ì— í•­ìƒ í¬í•¨)
- `snippet_text`: ì¶”ì¶œëœ ë³¸ë¬¸ ì¼ë¶€ (100~300ì)
- `position`: `"start"` | `"early_middle"` | `"middle"` | `"late_middle"` | `"end"`
- `snippet_length`: ì‹¤ì œ ìŠ¤ë‹ˆí« ê¸¸ì´
- `label`: ì›ë³¸ ê¸€ì˜ ë¼ë²¨ ìƒì†
- `confidence`: ì›ë³¸ ê¸€ì˜ confidence ìƒì†
- `keyword`: ì›ë³¸ ê¸€ì˜ ê²€ìƒ‰ í‚¤ì›Œë“œ
- `created_at`: ìŠ¤ë‹ˆí« ìƒì„± ì‹œê°

### í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜

```python
def split_into_snippets(
    full_text: str,
    min_length: int = 100,
    max_length: int = 300
) -> List[Dict]:
    """ì „ì²´ ê¸€ì„ 3~5ê°œ ìŠ¤ë‹ˆí«ìœ¼ë¡œ ë¶„í• 

    Args:
        full_text: ì›ë³¸ ê¸€ ì „ì²´ ë³¸ë¬¸
        min_length: ìµœì†Œ ìŠ¤ë‹ˆí« ê¸¸ì´
        max_length: ìµœëŒ€ ìŠ¤ë‹ˆí« ê¸¸ì´

    Returns:
        ìŠ¤ë‹ˆí« ë¦¬ìŠ¤íŠ¸ (position, text, length í¬í•¨)
    """
    text_len = len(full_text)
    num_snippets = get_num_snippets(text_len)

    positions = ["start", "early_middle", "middle", "late_middle", "end"][:num_snippets]
    snippets = []

    for i, pos in enumerate(positions):
        start_ratio = i / num_snippets
        end_ratio = (i + 1) / num_snippets

        start_idx = int(text_len * start_ratio)
        end_idx = int(text_len * end_ratio)

        # 100~300ì ë²”ìœ„ ì¡°ì •
        snippet = full_text[start_idx:start_idx + max_length]
        if len(snippet) < min_length and start_idx + min_length <= text_len:
            snippet = full_text[start_idx:start_idx + min_length]

        snippets.append({
            "position": pos,
            "text": snippet.strip(),
            "length": len(snippet.strip())
        })

    return snippets


def preprocess_all_blogs(
    input_file: Path,
    output_file: Path,
    min_length: int = 100,
    max_length: int = 300,
    limit: int = None  # í…ŒìŠ¤íŠ¸ìš©: ì²˜ìŒ Nê°œë§Œ ì²˜ë¦¬
) -> Dict[str, int]:
    """ì „ì²´ ë¼ë²¨ë§ ë°ì´í„° â†’ ìŠ¤ë‹ˆí« ë¶„í• 

    Args:
        input_file: data/labeled/labeled_blogs.json
        output_file: data/processed/training_data.json
        min_length: ìµœì†Œ ìŠ¤ë‹ˆí« ê¸¸ì´
        max_length: ìµœëŒ€ ìŠ¤ë‹ˆí« ê¸¸ì´
        limit: í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ì œí•œ (Noneì´ë©´ ì „ì²´ ì²˜ë¦¬)

    Returns:
        í†µê³„ ì •ë³´ (total_blogs, total_snippets, avg_snippets_per_blog)
    """
    pass
```

## ğŸ“ˆ ì˜ˆìƒ ê²°ê³¼ (ë™ì  ê³„ì‚°)

| ë‹¨ê³„ | ì…ë ¥ | ì¶œë ¥ | ì¦ê°• ë¹„ìœ¨ |
|------|------|------|----------|
| Phase 1 | Nê°œ ë¸”ë¡œê·¸ | Nê°œ ë¼ë²¨ë§ | 1.0x |
| Phase 2 | Nê°œ ë¼ë²¨ë§ | ~3.3Nê°œ ìŠ¤ë‹ˆí« | 3.3x |

**ì‹¤ì œ ìŠ¤ë‹ˆí« ìˆ˜ ê³„ì‚°**:
```python
total_snippets = sum(get_num_snippets(len(blog['full_text'])) for blog in blogs)
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ

### ì†Œê·œëª¨ ë°ì´í„° í…ŒìŠ¤íŠ¸

```bash
# 1. ì²˜ìŒ 10ê°œë§Œ ë¼ë²¨ë§
python scripts/labeler.py --limit 10

# 2. ë¼ë²¨ë§ëœ 10ê°œë§Œ ìŠ¤ë‹ˆí« ë¶„í• 
python scripts/preprocess.py --limit 10

# 3. ê²°ê³¼ í™•ì¸
python -c "
import json
with open('data/labeled/labeled_blogs.json') as f:
    labeled = json.load(f)
with open('data/processed/training_data.json') as f:
    snippets = json.load(f)
print(f'ë¼ë²¨ë§: {len(labeled)}ê°œ')
print(f'ìŠ¤ë‹ˆí«: {len(snippets)}ê°œ')
print(f'ì¦ê°• ë¹„ìœ¨: {len(snippets)/len(labeled):.1f}x')
"
```

### ì „ì²´ ë°ì´í„° ì²˜ë¦¬

```bash
# 1. ì „ì²´ ë¼ë²¨ë§ (limit ì—†ìŒ)
python scripts/labeler.py --api-key YOUR_GEMINI_KEY

# 2. ì „ì²´ ìŠ¤ë‹ˆí« ë¶„í• 
python scripts/preprocess.py

# 3. í†µê³„ í™•ì¸
python scripts/preprocess.py --stats
```

## âš™ï¸ CLI ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„

### `labeler.py`

```bash
# ê¸°ë³¸ ì‚¬ìš© (ì „ì²´ ì²˜ë¦¬)
python scripts/labeler.py --api-key YOUR_KEY

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì²˜ìŒ 10ê°œë§Œ)
python scripts/labeler.py --api-key YOUR_KEY --limit 10

# ë°°ì¹˜ í¬ê¸° ì¡°ì • (API rate limit ê³ ë ¤)
python scripts/labeler.py --api-key YOUR_KEY --batch-size 5

# í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì»¤ìŠ¤í„°ë§ˆì´ì§•
python scripts/labeler.py --api-key YOUR_KEY --prompt prompts/custom.md

# ì˜µì…˜ ì „ì²´
python scripts/labeler.py \
  --api-key YOUR_KEY \
  --input data/blogs.json \
  --output data/labeled/labeled_blogs.json \
  --prompt prompts/labeling_prompt.md \
  --batch-size 10 \
  --limit 50 \
  --verbose
```

### `preprocess.py`

```bash
# ê¸°ë³¸ ì‚¬ìš© (ì „ì²´ ì²˜ë¦¬)
python scripts/preprocess.py

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ì²˜ìŒ 10ê°œë§Œ)
python scripts/preprocess.py --limit 10

# ìŠ¤ë‹ˆí« ê¸¸ì´ ì»¤ìŠ¤í„°ë§ˆì´ì§•
python scripts/preprocess.py --min-length 150 --max-length 250

# í†µê³„ë§Œ ì¶œë ¥ (ì²˜ë¦¬ ì•ˆ í•¨)
python scripts/preprocess.py --stats

# ì˜µì…˜ ì „ì²´
python scripts/preprocess.py \
  --input data/labeled/labeled_blogs.json \
  --output data/processed/training_data.json \
  --min-length 100 \
  --max-length 300 \
  --limit 50 \
  --verbose
```

## ğŸ’° ë¹„ìš© ì¶”ì • (ë™ì )

**Gemini-2.5-flash-latest ìš”ê¸ˆ**: ~$0.15-0.25 / 1M tokens

**í† í° ê³„ì‚°**:
```python
avg_chars_per_blog = 2000  # í‰ê·  ê¸€ì ìˆ˜
tokens_per_blog = avg_chars_per_blog * 1.5  # í•œê¸€ì€ ì•½ 1.5 tokens/char
total_tokens = len(blogs) * tokens_per_blog
estimated_cost = (total_tokens / 1_000_000) * 0.20  # í‰ê·  $0.20/1M
```

**ì˜ˆì‹œ**:
- 100ê°œ ë¸”ë¡œê·¸: ~$0.006
- 1,000ê°œ ë¸”ë¡œê·¸: ~$0.06
- 10,000ê°œ ë¸”ë¡œê·¸: ~$0.60

## ğŸ¯ í’ˆì§ˆ ê²Œì´íŠ¸

### Phase 1 ì™„ë£Œ ì¡°ê±´
- âœ… ëª¨ë“  ë¸”ë¡œê·¸ ë¼ë²¨ë§ ì™„ë£Œ (ì‹¤íŒ¨ 0ê°œ)
- âœ… AI/HUMAN ë¹„ìœ¨: 40-60% (ê· í˜• í™•ì¸)
- âœ… í‰ê·  confidence > 0.7
- âœ… reasoning í•„ë“œ ëˆ„ë½ ì—†ìŒ
- âœ… JSON íŒŒì‹± ì˜¤ë¥˜ ì—†ìŒ

**ê²€ì¦ ì½”ë“œ**:
```python
def validate_phase1(labeled_file: Path) -> Dict[str, Any]:
    with open(labeled_file) as f:
        data = json.load(f)

    total = len(data)
    ai_count = sum(1 for x in data if x['label'] == 'AI')
    human_count = total - ai_count
    avg_confidence = sum(x['confidence'] for x in data) / total

    return {
        'total': total,
        'ai_ratio': ai_count / total,
        'human_ratio': human_count / total,
        'avg_confidence': avg_confidence,
        'passed': (
            0.4 <= ai_count / total <= 0.6 and
            avg_confidence > 0.7
        )
    }
```

### Phase 2 ì™„ë£Œ ì¡°ê±´
- âœ… ìŠ¤ë‹ˆí« ìƒì„± ë¹„ìœ¨: 3.0~3.5x (í‰ê·  3.3x)
- âœ… ëª¨ë“  snippet ê¸¸ì´: 100~300ì
- âœ… ì›ë³¸ blog_id ì¶”ì  ê°€ëŠ¥
- âœ… ë¼ë²¨ ë¶„í¬ ìœ ì§€ (Â±5% ì˜¤ì°¨)
- âœ… position í•„ë“œ ëˆ„ë½ ì—†ìŒ

**ê²€ì¦ ì½”ë“œ**:
```python
def validate_phase2(
    labeled_file: Path,
    snippet_file: Path
) -> Dict[str, Any]:
    with open(labeled_file) as f:
        labeled = json.load(f)
    with open(snippet_file) as f:
        snippets = json.load(f)

    total_blogs = len(labeled)
    total_snippets = len(snippets)
    augmentation_ratio = total_snippets / total_blogs

    # ê¸¸ì´ ê²€ì¦
    length_valid = all(
        100 <= s['snippet_length'] <= 300
        for s in snippets
    )

    # ë¼ë²¨ ë¶„í¬ ê²€ì¦
    original_ai_ratio = sum(1 for x in labeled if x['label'] == 'AI') / total_blogs
    snippet_ai_ratio = sum(1 for x in snippets if x['label'] == 'AI') / total_snippets
    label_distribution_match = abs(original_ai_ratio - snippet_ai_ratio) < 0.05

    return {
        'total_blogs': total_blogs,
        'total_snippets': total_snippets,
        'augmentation_ratio': augmentation_ratio,
        'length_valid': length_valid,
        'label_distribution_match': label_distribution_match,
        'passed': (
            3.0 <= augmentation_ratio <= 3.5 and
            length_valid and
            label_distribution_match
        )
    }
```

## ğŸ”„ ì¬ì‹¤í–‰ ë° ì¤‘ë³µ ë°©ì§€

### ë¶€ë¶„ ì¬ì‹¤í–‰ ì§€ì›

**Phase 1 (ë¼ë²¨ë§)**:
- ê¸°ì¡´ `labeled_blogs.json` ì¡´ì¬ ì‹œ â†’ ì´ë¯¸ ë¼ë²¨ë§ëœ blog_idëŠ” ìŠ¤í‚µ
- ìƒˆë¡œìš´ ë¸”ë¡œê·¸ë§Œ ë¼ë²¨ë§í•˜ì—¬ ì¶”ê°€

```python
def load_existing_labels(output_file: Path) -> Dict[str, Dict]:
    """ê¸°ì¡´ ë¼ë²¨ë§ ë°ì´í„° ë¡œë“œ"""
    if not output_file.exists():
        return {}

    with open(output_file) as f:
        existing = json.load(f)

    return {blog['blog_id']: blog for blog in existing}
```

**Phase 2 (ìŠ¤ë‹ˆí« ë¶„í• )**:
- ê¸°ì¡´ `training_data.json` ì¡´ì¬ ì‹œ â†’ ì´ë¯¸ ë¶„í• ëœ blog_idëŠ” ìŠ¤í‚µ
- ìƒˆë¡œìš´ ë¼ë²¨ë§ ë°ì´í„°ë§Œ ìŠ¤ë‹ˆí« ë¶„í• 

```python
def load_existing_snippets(output_file: Path) -> Set[str]:
    """ì´ë¯¸ ìŠ¤ë‹ˆí« ë¶„í• ëœ blog_id ì¶”ì¶œ"""
    if not output_file.exists():
        return set()

    with open(output_file) as f:
        snippets = json.load(f)

    return {s['original_blog_id'] for s in snippets}
```

## ğŸ“Š ë¡œê¹… ë° í†µê³„

### ë¡œê¹… í˜•ì‹

```python
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    handlers=[
        logging.FileHandler('logs/preprocessing.log'),
        logging.StreamHandler()
    ]
)

# ì˜ˆì‹œ ë¡œê·¸
# 2025-10-16 19:00:00 [INFO] Phase 1 ì‹œì‘: 500ê°œ ë¸”ë¡œê·¸ ë¼ë²¨ë§
# 2025-10-16 19:00:10 [INFO] ë°°ì¹˜ 1/50 ì™„ë£Œ (10ê°œ ì²˜ë¦¬, í‰ê·  confidence: 0.82)
# 2025-10-16 19:05:00 [INFO] Phase 1 ì™„ë£Œ: AI 210ê°œ (42%), HUMAN 290ê°œ (58%)
# 2025-10-16 19:05:05 [INFO] Phase 2 ì‹œì‘: 500ê°œ ë¸”ë¡œê·¸ â†’ ìŠ¤ë‹ˆí« ë¶„í• 
# 2025-10-16 19:05:15 [INFO] Phase 2 ì™„ë£Œ: 1,650ê°œ ìŠ¤ë‹ˆí« ìƒì„± (3.3x)
```

### í†µê³„ ì¶œë ¥ í˜•ì‹

```bash
$ python scripts/labeler.py --stats

=== Phase 1 í†µê³„ ===
ì…ë ¥: 500ê°œ ë¸”ë¡œê·¸
ì¶œë ¥: 500ê°œ ë¼ë²¨ë§ ì™„ë£Œ
- AI: 210ê°œ (42%)
- HUMAN: 290ê°œ (58%)
- í‰ê·  confidence: 0.82
- ì‹¤íŒ¨: 0ê°œ
ë¹„ìš©: ~$0.12
ì†Œìš” ì‹œê°„: 5ë¶„ 23ì´ˆ

$ python scripts/preprocess.py --stats

=== Phase 2 í†µê³„ ===
ì…ë ¥: 500ê°œ ë¼ë²¨ë§ ë°ì´í„°
ì¶œë ¥: 1,650ê°œ ìŠ¤ë‹ˆí«
- ì¦ê°• ë¹„ìœ¨: 3.3x
- í‰ê·  snippet ê¸¸ì´: 185ì
- 3ê°œ ë¶„í• : 150ê°œ ë¸”ë¡œê·¸
- 4ê°œ ë¶„í• : 250ê°œ ë¸”ë¡œê·¸
- 5ê°œ ë¶„í• : 100ê°œ ë¸”ë¡œê·¸
ë¼ë²¨ ë¶„í¬: AI 693ê°œ (42%), HUMAN 957ê°œ (58%)
ì†Œìš” ì‹œê°„: 12ì´ˆ
```

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„: ML í•™ìŠµ

ì „ì²˜ë¦¬ ì™„ë£Œ í›„ ë‹¤ìŒ ë‹¨ê³„:

1. **Train/Test ë¶„í• **: `training_data.json` â†’ 80% train, 20% test
2. **ëª¨ë¸ í•™ìŠµ**: TF-IDF + Logistic Regression (MVP)
3. **ëª¨ë¸ í‰ê°€**: Accuracy, Precision, Recall, F1
4. **CoreML ë³€í™˜**: Safari í™•ì¥ í†µí•©

**ê´€ë ¨ ë¬¸ì„œ**: (ì¶”í›„ ì‘ì„± ì˜ˆì •)
- `docs/ml-training-plan.md`
- `docs/coreml-conversion.md`

---

**ì‘ì„±ì¼**: 2025-10-16
**ë²„ì „**: 1.0
**ì‘ì„±ì**: Claude Code
